Meta-analyses in psychology often pool outcomes measured using different instruments, with many studies reporting only a subset of these outcomes. 
Such instruments typically measure the same underlying construct and are statistically correlated, making multivariate meta-analysis a methodologically appropriate choice. 
However, missing outcomes raise concerns about bias and inference validity, particularly when the mechanism driving missingness is unknown. 
While some outcomes may be Missing Completely at Random (MCAR) or Missing at Random (MAR), a more complex scenario arises when outcomes are Missing Not At Random (MNAR).

Missing study-level summary statistics are handled by repeated stochastic single imputation: in each Monte-Carlo replicate every absent effect estimate, standard error, 
and within-study correlation is replaced by a single random draw from one of four donor distributions—uniform, univariate normal, multivariate normal, 
or truncated normal—selected to represent a spectrum of plausible data-generating processes while preserving cross-outcome dependence where appropriate.
These imputations are embedded in a multiverse sensitivity design that systematically varies both the assumed missingness mechanism (MCAR, MAR, MNAR) 
and the meta-analytic specification across thousands of replicates.

The multiverse approach offers several advantages. It retains the observed correlation structure, prevents artificial distortion of heterogeneity, 
remains computationally lightweight, and makes the dependence of inferences on unverifiable assumptions fully transparent. 
Simulations show that misspecifying the mechanism (e.g., analysing MNAR data as MAR) yields biased pooled effects and under-coverage, 
whereas structurally coherent imputation models improve inferential accuracy. We conclude with practical recommendations and reproducible code for conducting 
multiverse sensitivity analyses in psychological MVMA when outcome-level missingness and uncertainty about its mechanism are present.










